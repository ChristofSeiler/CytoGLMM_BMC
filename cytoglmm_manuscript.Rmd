---
title: "`CytoGLMM`: Conditional Differential Analysis for Flow and Mass Cytometry Experiments"
author: "Christof Seiler$^{123}$, Anne-Maud Ferreira$^3$, Lisa M. Kronstad$^{457}$, Laura J. Simpson$^{45}$, \\\n Mathieu Le Gars$^{45}$, Elena Vendrame$^{45}$, Catherine A. Blish$^{456}$, and Susan Holmes$^3$"
date: "$^1$Department of Data Science and Knowledge Engineering, Maastricht University \\\n $^2$Mathematics Centre Maastricht, Maastricht University \\\n $^3$Department of Statistics, Stanford University \\\n $^4$Immunology Program, Stanford University School of Medicine \\\n $^5$Department of Medicine, Stanford University School of Medicine \\\n $^6$Chan Zuckerberg Biohub, San Francisco \\\n $^7$Department of Microbiology and Immunology, Midwestern University \\\n \\\n `r format(Sys.time(), '%B %d, %Y')`"
header-includes:
  - \usepackage{setspace}
  - \doublespacing
  - \usepackage{lineno}
  - \linenumbers
  - \usepackage{xcolor}
output:
  bookdown::pdf_document2: 
    toc: false
  bookdown::word_document2: 
    toc: false
bibliography: cytoglmm_manuscript.bib
abstract: |
  **Background:** Flow and mass cytometry are important modern immunology tools for measuring expression levels of multiple proteins on single cells. The goal is to better understand the mechanisms of responses on a single cell basis by studying differential expression of proteins. \textcolor{red}{Most current data analysis tools compare expressions across many computationally discovered cell types. Our goal is to focus on just one cell type. Our narrower field of application allows us to define a more specific statistical model with easier to control statistical guarantees.} **Results:** Differential analysis of marker expressions can be difficult due to marker correlations and inter-subject heterogeneity, particularly for studies of human immunology. We address these challenges with two multiple regression strategies: A bootstrapped generalized linear model and a generalized linear mixed model. On simulated datasets, we compare the robustness towards marker correlations and heterogeneity of both strategies. For paired experiments, we find that both strategies maintain the target false discovery rate under medium correlations and that mixed models are statistically more powerful under the correct model specification. For unpaired experiments, our results indicate that much larger patient sample sizes are required to detect differences. We illustrate the `CytoGLMM` _R_ package and workflow for both strategies on a pregnancy dataset. **Conclusions:** Our approach to finding differential proteins in flow and mass cytometry data reduces biases arising from marker correlations and safeguards against false discoveries induced by patient heterogeneity.
---

**Keywords:** High-Dimensional Cytometry, Generalized Linear Models, Generalized Linear Mixed Models
**Corresponding author:** Christof Seiler (christof.seiler@maastrichtuniversity.nl)

```{r load_packages, echo=FALSE, warning=FALSE, message=FALSE}
library("CytoGLMM")
library("tidyverse")
library("magrittr")
library("broom")
library("RColorBrewer")
library("cowplot")
library("ggthemes")
library("MASS")
library("SummarizedExperiment")
library("logging")
library("lme4")
library("glmnet")
library("multcomp")
library("batchtools")
library("Matrix")
library("binaryLogic")
theme_set(theme_few())
setLevel("ERROR", container = "mbest.mhglm")
setLevel("ERROR", container = "mbest.mhglm.fit")
source("data.R")
source("experiment.R")
source("plotting.R")
```

# Background

Flow [@saeys2016computational] and mass cytometry [@bendall2011single] allow researchers to simultaneously assess expression patterns of a large number of proteins on individual cells, allowing deep interrogation of cellular responses. The goal of such studies is to improve our understanding of the response mechanisms on a single cell basis by defining protein expression patterns that are associated with a particular stimulus or experimental condition. Finding differentially expressed proteins can help identify how cells function across experimental conditions. \textcolor{red}{Some examples from our own work include: comparison between influenza strains} [@kronstad2018differential]\textcolor{red}{, comparison between pregnant and non-pregnant women} [@legars2019pregnancy]\textcolor{red}{, comparison between healthy controls and HIV+ individuals} [@vendrame2019tigit]\textcolor{red}{, comparison between multiple sclerosis patients treated with daclizumab beta or placebo} [@ranganath2020characterization]\textcolor{red}{, and comparison between Beninese sex workers and healthy controls} [@zhao2020natural].

Statistical workflows that analyze data generated by flow and mass cytometry usually begin by clustering cells into both known and novel cell types. 
<!--
Clustering algorithms: [@lo2009flowclust; @finak2009merging; @qian2010elucidation; @zare2010data; @aghaeepour2011rapid; @qiu2011extracting; @ge2012flowpeaks; @shekhar2014automatic; @becher2014high; @naim2014swift; @meehan2014autogate; @van2015flowsom; @sorensen2015immunoclust; @levine2015data; @chen2016cytofkit; @samusik2016automated; @lee2017automated; @li2017gating; @theorell2019determination; @abdelaal2019predicting] and
-->
@weber2016comparison \textcolor{red}{provide an informative benchmark comparison study of many of the current clustering algorithms.} The cluster step is followed by a differential expression analysis between and within cell types. The most popular differential analysis tools are: `Citrus` [@bruggner2014automated], the `Bioconductor workflow` by @nowicka2017cytof, `cydar` [@lun2017testing], `CellCnn` [@arvaniti2017sensitive], and `diffcyt` [@weber2019diffcyt].

We can classify differential analysis methods into marginal regression---analyses that focus on individual markers---and multiple regression---analyses that work on multiple markers simultaneously. The `Bioconductor workflow` by @nowicka2017cytof, `cydar`, and `diffcyt` are marginal regression methods. The advantage of marginal regression approaches is that they allow for flexible experimental designs\textcolor{red}{---multiple factors, designs with interactions, designs with continuous variables, splines, and others are possible}. The main disadvantage of this approach is in the separate testing for differential expression for each protein---when studying a specific protein marker---all the other markers are ignored. Therefore these methods are susceptible to biases induced by marker correlations.

`Citrus` and `CellCnn` are multiple regression methods. Their advantage is that they can provide a conditional interpretation of the effect of a protein onto the outcome, and thus reduce the bias due to marker correlations. A disadvantage is that `Citrus` summarizes protein expressions by taking the median for each cell type which can lead to a decrease in statistical power. The power decrease comes from the reduction in cell sample size from thousands of cells to one cell per sample. On the other hand, `CellCnn` uses a neural network for which it is currently unclear how to build confidence intervals, derive $p$-values, and control the number of falsely reported markers.

It is helpful to consider an example to further illustrate the differences between the marginal and the multiple regression method. \textcolor{red}{Consider two intracellular proteins involved in interferon-$\gamma$ mediated signaling,} *\textcolor{red}{STAT1}* and *\textcolor{red}{IRF1}*. Assume that applying a stimulus to *\textcolor{red}{STAT1}* activates transcription of *\textcolor{red}{IRF1}*. Further assume that the stimulus does not directly activate *\textcolor{red}{IRF1}*. If we performed separate differential analyses on protein *\textcolor{red}{STAT1}* and *\textcolor{red}{IRF1}*, we would observe differential expressions for both *\textcolor{red}{STAT1}* and *\textcolor{red}{IRF1}*, even though only *\textcolor{red}{STAT1}* had been directly activated. In contrast, a multiple regression method would report *\textcolor{red}{STAT1}* as differentially expressed given *\textcolor{red}{IRF1}*, and *\textcolor{red}{IRF1}* as not differentially expressed given *\textcolor{red}{STAT1}*.

`CytoGLMM` implements multiple regression that accounts for marker correlations without the aforementioned limitations. The main difference between our method and current methods is that we focus on cell-specific differential analysis and one fixed cell type, whereas current methods (`Citrus`, `CellCnn`, `cydar`, and `diffcyt`) learn cell types and perform differential analysis jointly. The narrower field of application allows us to define a more specific statistical model with easier to control statistical guarantees. Only the `Bioconductor workflow` by @nowicka2017cytof focuses on specific cell types, but as mentioned before, they employ marginal regression which makes comparison to our multiple regression method difficult; as the two methods have different aims.

We present two versions of multiple regression: (i) A Generalized Linear Model (GLM) for unpaired samples. A GLM is a regression model that allows for a response and error terms that follow different distributions than the normal. (ii) A restricted Generalized Linear Mixed Model (GLMM), which is a GLM that allows for random and fixed effects, for paired samples---when the same donor provides two samples, one for each condition. \textcolor{red}{GLMs and GLMMs are generalizations of least squares to non-normal data. In our case, we will use logistic regression to model the experimental condition as unfair coin flips---when the coin flip comes up heads then the cell is declared to be stimulated, otherwise it is unstimulated. We model the coin fairness with a linear model of marker expressions after applying a transformation that ensures each coin flip has a probability of heads between zero and one.}

\textcolor{red}{Our models depart from the classic model where the marker expressions are the response variables. In our GLMs, the experimental condition is independent of the marker expression of interest given the other markers if the regression coefficient is zero} (Proposition 2.2 in @candes2018panning). In contrast, the usual marginal regression analysis does not allow for such conditional statements. For instance, it would not allow us to rule out markers that are merely correlated with other makers but are independent of the experimental condition---as illustrated with the example earlier.

In summary, our two main contributions are:

1. We present a conditional differential analysis to avoid biases arising from marker correlations by using multiple regression instead of marginal regression.
2. We present two multiple regression strategies that work with the unsummarized expression data to maximize statistical power and account for patient heterogeneity to safeguard against false discoveries: (i) GLMs with a patient-level bootstrap, and (ii) GLMMs with a patient-level random effect.

Section \@ref(results) evaluates the statistical properties of both strategies implemented in our _R_ package `CytoGLMM` on different simulated datasets, and illustrates the full workflow for real pregnancy data. In Section \@ref(discussion), we discuss our results in terms of biases and confounders. In Section \@ref(methods), we review the statistical background for GLMs and GLMMs.

# Results

We first evaluate the GLM and GLMM procedures for both paired and unpaired samples on simulated datasets. We then test them on a real pregnancy dataset.

## Simulated Datasets

We generate simulated data with both cell and donor level variability. We allow for negative and positive correlations between markers and a wide range of correlation strengths. We simulate different scenarios ranging from weak to strong patient/cell variability. To make sure that we generate positive counts we use a Poisson noise model after transforming the generated expressions to positive real numbers using the exponential function. This is similar to using the log link function for Poisson GLMs. Overall, there are four main parameters: correlation $\rho_B$ and standard deviation $\sigma_B$ at the cell level, and correlation $\rho_U$ and standard deviation $\sigma_U$ at the donor level. Additionally, we can regulate the number of cells per sample and the number of donors per dataset. The differential expression signal is induced by shifting the mean vector on the logarithmic scale. \textcolor{red}{We study the differential expression of three out of 10 markers after simulating exposure of cells to an experimental condition with two levels: stimulated versus unstimulated cells.} Section \@ref(construction-of-simulated-datasets) \textcolor{red}{provides a detailed mathematical description of the statistical model for the simulated datasets.}

```{r echo=FALSE, eval=FALSE}
# run on cluster
slurm_settings = "slurm_batchtools.tmpl"
current_time = Sys.time() %>%
  str_replace_all(":","") %>%
  str_replace_all("-| ","_")
reg = makeRegistry(file.dir = paste0("registry_",current_time),
                   source = c("diffcyt.R"),
                   packages = c("CytoGLMM", "tidyverse", "magrittr", "MASS", 
                                "lme4", "multcomp", "Matrix", "binaryLogic",
                                "glmnet"))
#reg$cluster.functions = makeClusterFunctionsMulticore(ncpus = 8)
reg$cluster.functions = makeClusterFunctionsSlurm(slurm_settings, 
                                                  scheduler.latency = 30,
                                                  fs.latency = 30)
saveRegistry(reg)
tb_args_paired = tidyr::crossing(
  n_sample = 16,
  fdr = 0.05,
  pi = 0,
  paired = TRUE,
  beta_treatment = log(24.7),
  beta_control = log(22.9),
  n_markers = 10,
  bias = 0,
  n_true = 3,
  rho_b = -seq(0, 0.8, 0.4),
  rho_u = -seq(0, 0.8, 0.4),
  sigma_b = seq(0, 1, 0.5),
  sigma_u = seq(0, 1, 0.5),
  n_cells = 1000,
  seed = 1:100
  )
tb_args_unpaired = tidyr::crossing(
  n_sample = 16, # seq(4, 32, 2)
  fdr = 0.05,
  pi = 0,
  paired = FALSE,
  beta_treatment = log(22.9+15),
  beta_control = log(22.9),
  n_markers = 10,
  bias = 0,
  n_true = 3,
  rho_b = -seq(0, 0.8, 0.4), # 0
  rho_u = -seq(0, 0.8, 0.4), # 0
  sigma_b = seq(0, 1, 0.5), # 1
  sigma_u = seq(0, 1, 0.5), # 1
  n_cells = 1000,
  seed = 1:100
  )
tb_args_n_sample = tidyr::crossing(
  n_sample = seq(8, 32, 2),
  fdr = 0.05,
  pi = 0,
  paired = TRUE,
  beta_treatment = log(24.7),
  beta_control = log(22.9),
  n_markers = 10,
  bias = 0,
  n_true = 3,
  rho_b = 0,
  rho_u = 0,
  sigma_b = 1,
  sigma_u = 1,
  n_cells = c(100,500,1000,2000,10000),
  seed = 1:100
  )
#tb_args = bind_rows(tb_args_paired, tb_args_unpaired)
tb_args = tb_args_n_sample
ids =  batchMap(fun = experiment, args = tb_args, reg = reg)
n_chunks = 900
time_per_experiment = 20 # in minutes
ids[, chunk := chunk(job.id, n.chunks = n_chunks)] # group into 900 chunks
submitJobs(ids = ids, reg = reg,
           resources = list(ncpus = 1, # cores per job
                            memory = 8000, # MB memory per job
                            walltime = round(nrow(tb_args)/n_chunks*time_per_experiment) # minutes per job
                            ))
# expires only after 7 days to handle cluster instability
waitForJobs(sleep = 60, expire.after = 10080)
getStatus(reg = reg)
findErrors(reg = reg)
getErrorMessages(reg = reg)
# by setting missing.val to NULL, we impute failed jobs with NULL
tb_experiment = reduceResultsList(missing.val = NULL, reg = reg) %>% bind_rows()
#write_csv(tb_experiment, path = "tb_experiment_paired_unpaired.csv")
write_csv(tb_experiment, path = "tb_experiment_n_sample.csv")
# clean up
#removeRegistry()
```

```{r echo=FALSE, message=FALSE, eval=TRUE}
tb_experiment_paired_unpaired = read_csv("tb_experiment_paired_unpaired.csv")
tb_experiment_n_sample = read_csv("tb_experiment_n_sample_citrus_lambda_min.csv")
```

```{r echo=FALSE, message=FALSE}
tb_summary = tb_experiment_paired_unpaired %>% 
  group_by(fdr, paired, n_markers, beta_treatment, beta_control, bias, 
           n_true, rho_b, rho_u, sigma_b, sigma_u, n_cells, method) %>% 
  summarize(FDR = mean(fdp), power = mean(power)) %>%
  ungroup()
tb_summary %<>% mutate(effect_size = round(
  exp(beta_treatment) - exp(beta_control), digits = 1)
  )
```

We perform simulations with a variety of different parameters. All simulations have 16 samples. For paired samples, those 16 samples come from 8 donors. For unpaired samples, those 16 samples come from 16 donors. Each sample has 1,000 cells. We compared the observed False Discovery Rate (FDR) and the power. The FDR measures the statistical type 1 errors, the expected proportion of falsely declared discoveries over the total number of reported discoveries. The statistical power represents the proportion of correctly reported discoveries over the total number of true discoveries.

```{r experiment-paired, echo=FALSE, fig.height=5, fig.width=10, out.width="100%", fig.align="center", eval=TRUE, fig.cap="Summary of experiments with 1,000 cells per sample averaged over 100 runs. The horizontal dashed line represents the target FDR. Postfixes BH and BY stand for the respective FDR control procedure. Subscripts $B$ and $U$ indicate cell and donor-level standard deviation $\\sigma$ and correlation $\\rho$, respectively.", fig.wide=FALSE, warning=FALSE}
plot_grid(
  plot_cor(tb_summary %>% 
             filter(method %in% c("GLM-BH", "GLM-BY", "GLMM-BH", "GLMM-BY")), 
           .sigma_b = 1, .sigma_u = 1, .paired = TRUE),
  plot_sig(tb_summary %>% 
             filter(method %in% c("GLM-BH", "GLM-BY", "GLMM-BH", "GLMM-BY")), 
           .rho_b = 0, .rho_u = 0, .paired = TRUE)  
)
```

```{r experiment-unpaired, echo=FALSE, fig.height=5, fig.width=10, out.width="100%", fig.align="center", eval=TRUE, fig.cap="Summary of experiments with 1,000 cells per sample averaged over 100 runs. The horizontal dashed line represents the target FDR. Postfixes BH and BY stand for the respective FDR control procedure. Subscripts $B$ and $U$ indicate cell and donor-level standard deviation $\\sigma$ and correlation $\\rho$, respectively.", fig.wide=FALSE, warning=FALSE}
plot_grid(
  plot_cor(tb_summary %>% 
             filter(method %in% c("GLM-BH", "GLM-BY")),
           .sigma_b = 1, .sigma_u = 1, .paired = FALSE),
  plot_sig(tb_summary %>% 
             filter(method %in% c("GLM-BH", "GLM-BY")), 
           .rho_b = 0, .rho_u = 0, .paired = FALSE)
)
```

Figures \@ref(fig:experiment-paired) and \@ref(fig:experiment-unpaired) show a summary averaged over 100 runs for paired sample and unpaired sample experiments with effect size $\delta_p^{(1)}-\delta_p^{(0)} = 1.8$ and $\delta_p^{(1)}-\delta_p^{(0)} = 15$, respectively, and varying standard deviation $\sigma$ and correlation $\rho$ parameters. The dashed lines indicate the target FDR of $0.05$. 

First, let's consider the paired samples experiment. The plots on the left show results when we vary cell and donor-level correlations at a fixed amount of cell $\sigma_B = 1$ and donor $\sigma_U = 1$ marker standard deviations. We observe only small differences across donor correlations $\rho_U$ of a small increase of power with increasing correlation. In contrast, there are large increases of power as a function of cell correlations $\rho_B$. In the panel of plots on the right, we set both correlations to zero and vary the marker standard deviations. In this setting, we again observe major changes with increasing standard deviations at the cell-level $\sigma_B$: the larger the cell-level variability, the lower the power. This is also true for donor-level variability, though to a much lesser extent. FDR is controlled below its target level under medium cell-level marker correlations ($| \rho_B | \le  0.4$) except when cell variability is at zero $\sigma_B = 0$, and donor variability is at one $\sigma_U = 1$. As expected, the Benjamini–Yekutiel (BY) procedure is more conservative than the Benjamini-Hochberg (BH) procedure, that is both FDR and power are lower. Interestingly, power increases with cell-level correlations $\rho_B$, and is virtually unaffected by donor-level correlations $\rho_U$.
<!--
Additional simulation experiments on null-data showed that the $p$-values under zero effect size $\delta$ a skewed toward one with a non-zero cell-level variation. 
-->
Overall, GLMM methods are more powerful than GLM methods. Figure \@ref(fig:experiment-nsamples) shows simulations for power and FDR with varying numbers of \textcolor{red}{cells per samples and} paired samples. Both cell and donor standard deviations are set to $\sigma_B = \sigma_U = 1$, and correlations are set to $\rho_B = \rho_U = 0$. \textcolor{red}{We use the same effect size of $\delta_p^{(1)}-\delta_p^{(0)} = 1.8$ as in the experiment of Figure} \@ref(fig:experiment-paired). An efficiency gain is clearly visible when we compare how many paired samples are needed to achieve 80% power. \textcolor{red}{We observe that with 1000 cells,} GLMM-BH needs seven paired samples to exceed the 80% power threshold, whereas GLM-BH needs 13 paired samples to achieve the same. \textcolor{red}{We can also see that GLMM-BH achieves adequate power with as few as 1000 cells per sample. We add results for \texttt{Citrus} to illustrate the power gain. Note that we chose the regularization parameter using leave-one-out cross-validation and select the parameter with the smallest prediction error. The original \texttt{Citrus} implementation chooses the regularization parameter using an FDR calculation. In our simulation study, the original procedure yields zero power across all sample sizes.}

```{r experiment-nsamples, echo=FALSE, fig.height=5, fig.width=10, out.width="100%", fig.align="center", eval=TRUE, fig.cap="\\textcolor{red}{Summary of experiments with varying number of cells per sample averaged over 100 runs.} Power: The horizontal dashed line represents a power of 0.8. FDR: The horizontal dashed line represents the target FDR of 0.05.", fig.wide=FALSE, warning=FALSE, message=FALSE}
tb_experiment_n_sample %<>% filter(paired)
methods = c("GLM-BH", "GLM-BY", "GLMM-BH", "GLMM-BY", "Citrus")
tb_experiment_n_sample %<>% filter(method %in% methods)
tb_experiment_n_sample$method %<>% factor(methods)
tb_summary = tb_experiment_n_sample %>% 
  group_by(fdr, paired, n_markers, beta_treatment, beta_control, bias, 
           n_true, rho_b, rho_u, sigma_b, sigma_u, n_cells, method, n_samples) %>% 
  summarize(FDR = mean(fdp), power = mean(power)) %>%
  ungroup()
tb_summary %<>% mutate(effect_size = round(
  exp(beta_treatment) - exp(beta_control), digits = 1)
  )
tb_summary %<>% mutate(n_pairs = n_samples/2)
p_power = ggplot(tb_summary, aes(n_pairs, power, color = method)) +
  geom_line() + 
  geom_point() +
  geom_hline(yintercept = 0.8, linetype = "dashed", alpha = 0.5) +
  geom_vline(xintercept = c(7, 13), linetype = "dashed", alpha = 0.5) +
  facet_wrap(~n_cells, nrow = 1, labeller = "label_both") +
  ggtitle("Power") +
  scale_color_few() +
  theme(axis.title.y = element_blank(), panel.spacing.x = unit(1, "lines")) +
  ylim(0, 1)
p_fdr = ggplot(tb_summary, aes(n_pairs, FDR, color = method)) +
  geom_line() + 
  geom_point() +
  geom_hline(yintercept = unique(tb_summary$fdr), linetype = "dashed", alpha = 0.5) +
  ggtitle("FDR") +
  facet_wrap(~n_cells, nrow = 1, labeller = "label_both") +
  scale_color_few() +
  theme(axis.title.y = element_blank(), panel.spacing.x = unit(1, "lines"))# +
  #ylim(0, 0.05)
plot_grid(p_power, p_fdr, nrow = 2)
```

In the unpaired samples experiment, we only show GLM results as the GLMM results have zero power, there is no data to estimate the donor-level random effect term. We observe up to 20% FDR with a target FDR of 5%. To have non-zero power we need to increase the effect size to 15 (in comparison, for paired experiments the effect size is set to 1.8). Furthermore, FDR is only controlled under medium cell-level marker correlations using the more conservative BY procedure, with BH exceeding $0.05$ in most scenarios except when we have zero donor-level variability $\sigma_U = 0$. As before, BY comes with a loss of power. 

## Experimental Dataset

We reanalyze a published dataset on the maternal immune system during pregnancy [@aghaeepour2017immune]. The study provides a rich mass cytometry dataset collected at four time points during pregnancy in two cohorts. The authors isolated cells from blood samples and stimulated them with several activation factors. The goal was to explain how immune cells react to these stimuli, and how these reactions change throughout pregnancy. Findings from such experiments might identify immunological deviations implicated in pregnancy-related pathologies.

The data were collected at early, mid, late pregnancy, and six weeks postpartum. Samples were left unstimulated or stimulated. Stimulation conditions included: $\text{interferon-}\alpha\text{2A}$ ($\text{IFN}\alpha$), lipopolysaccharide, and a cocktail of interleukins (ILs) containing IL-2 and IL-6. They processed the samples on a CyTOF 2.0 mass cytometer instrument, and bead normalized the data to account for signal variation over time from changes in instrument performance [@finck2013normalization].

In our analysis, we focus on comparing early (first trimester, $Y_i = 0$) with late (third trimester, $Y_i = 1$) pregnancy samples stimulated with IFN$\alpha$ in the first cohort of 16 women. We gate cells into cell types and organize them in a data frame. We follow the gating scheme detailed in [@aghaeepour2017immune] and define 12 cell types using the _R_ package `openCyto` [@finak2014opencyto]:
memory CD4 positive T cells (CD4+Tmem), naive CD4 positive T cells (CD4+Tnaive),
memory CD8 positive T cells (CD8+Tmem), naive CD8 positive T cells (CD8+Tnaive),
$\gamma\delta$T cells (gdT), regulatory T memory cells (Tregsmem), regulatory T naive cells (Tregsnaive), B cells, classical monocytes (cMC), intermediate monocytes (intMC), non-classical monocytes (ncMC), and Natural Killer cells (NK). Out of the 32 protein markers measured on each cell, the authors defined 22 markers as gating markers, and 10 as functional markers. The functional markers are pSTAT1, pSTAT3, pSTAT5, pNF$\kappa$B, total I$\kappa$B, pMAPKAPK2, pP38, prpS6, pERK1/2, and pCREB (in plots Greek symbols are replaced by Latin symbols). 

We plot the maximum likelihood (for GLMs) and the method of moments estimates (for GLMMs) with 95\% confidence intervals for the fixed effects $\boldsymbol{\beta}$ (Figure \@ref(fig:pregnancy)). \textcolor{red}{We transform the raw counts using four different transformations---a $\log$ transform and three \texttt{asinh} transforms with varying cofactor. The estimates are on the $\log$-odds scale. All four transformations show similar trends. The $\log$ transform is between the \texttt{asinh} with cofactor 1 and 5.} We see that pSTAT1 is a strong predictor of the third trimester. \textcolor{red}{With the standard cofactor of 5,} this means that one unit increase in the transformed marker expression makes it between $\exp(1) = 2.7$ to $\exp(1.5) = 4.5$ (95\% confidence interval for GLMM) more likely to be a cell from the third trimester, while holding the other markers constant. pSTAT3 and pSTAT5 have negative coefficients. This means pSTAT3 and pSTAT5 predict the first trimester, while holding the other markers constant. Only pSTAT1, pSTAT3, and pSTAT5 are below an FDR of 0.05. Our results corroborate previous findings by @aghaeepour2017immune reporting an increase of pSTAT1 during the third trimester for IFN$\alpha$ stimulated samples.

```{r echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
df = load_data()
protein_names = names(df)[4:13]
df %<>% dplyr::filter(celltype == "NK")

extract_coefs = function(df) {
  glm_fit = CytoGLMM::cytoglm(df,
                              num_boot = 1000,
                              protein_names = protein_names,
                              condition = "condition",
                              group = "donor")
  glmm_fit = CytoGLMM::cytoglmm(df, 
                                protein_names = protein_names, 
                                condition = "condition", 
                                group = "donor")
  bind_rows(
    plot(glm_fit)$data %>% 
      dplyr::select(protein_name, estimate = coeff_median, low = min_median, high = max_median) %>%
      mutate(method = "cytoglm"),
    plot(glmm_fit)$data %>% 
      dplyr::select(protein_name, estimate = Estimate, low, high) %>%
      mutate(method = "cytoglmm")  
  )
}

asinh_1 = df %>% 
  dplyr::mutate_at(protein_names, function(x) asinh(x/1)) %>% 
  extract_coefs %>% 
  mutate(transform = "asinh(x)")
asinh_05 = df %>% 
  dplyr::mutate_at(protein_names, function(x) asinh(x/5)) %>% 
  extract_coefs %>%
  mutate(transform = "asinh(x/5)")
asinh_10 = df %>% dplyr::mutate_at(protein_names, function(x) asinh(x/10)) %>% 
  extract_coefs %>% 
  mutate(transform = "asinh(x/10)")
log_plus_1 = df %>% 
  dplyr::mutate_at(protein_names, function(x) log(x+1)) %>% 
  extract_coefs %>% 
  mutate(transform = "log(x+1)")
tb_coeff = bind_rows(asinh_1, asinh_05, asinh_10, log_plus_1)
tb_coeff$transform %<>% factor(c("log(x+1)", "asinh(x)", "asinh(x/5)", "asinh(x/10)"))
lab_str = df %>%
  pull(condition) %>%
  levels %>%
  paste(collapse = " <-> ")
```

```{r pregnancy, fig.height=4, fig.width=9, out.width="100%", fig.align="center", echo=FALSE, cache=TRUE, fig.cap="Methods comparison between bootstrap GLM (cytoglm) and GLMM (cytoglmm). The horizontal axes are on the log-odds scale. The vertical axes are the protein markers. \\textcolor{red}{Each color represents a different data transformation prior to the model fits.}", warning=FALSE}
ggplot(tb_coeff, aes(x = protein_name, y = estimate, color = transform)) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  geom_point(size = 2, position = position_dodge(width = 0.7)) +
  geom_errorbar(aes(ymin = low, ymax = high), position = position_dodge(width = 0.7)) +
  ylab(lab_str) +
  ylim(c(-0.9, 1.9)) +
  coord_flip() +
  scale_color_few() +
  theme(axis.title.y = element_blank()) + 
  facet_wrap(~method)
```

\textcolor{red}{The GLMM method takes one to two seconds for the pregnancy dataset with 178,872 NK cells. The GLM requires resampling the data multiple times. For 1000 bootstrap replicates it takes five minutes for the pregnancy dataset. We obtained these running times on a laptop with an 2.3 GHz quad-core processor.}

# Discussion

<!-- high level overview -->

Our new _R_ package `CytoGLMM` provides functions which are applicable to a wide range of cytometry studies. Besides comparisons on paired samples, where samples are available for the same subject under different experimental conditions, our `CytoGLMM` is applicable to unpaired samples, where samples are collected on two separate groups of individuals.

<!-- discuss simulation results -->

Our simulation experiments compare multiple regression GLM and GLMM, as implemented in `cytoglm` and `cytoglmm` in our _R_ package. In simulated paired samples experiments, both GLMM with Benjamini-Hochberg (GLMM-BH) and Benjamini–Yekutieli (GLMM-BY) procedures control the FDR below the target FDR under cell-level marker correlations with an autoregressive structure with correlations up to $\pm0.4$. GLMM methods are more powerful than GLM methods for paired samples. GLMM methods can account for the patient-to-patient variation in the model, whereas GLM methods treat this variation as noise, which results in noisier and thus less powerful estimates. For unpaired samples, we are forced to use the nonparametric bootstrap method for GLMs because there are no paired samples available to estimate the random effect term. In simulated unpaired experiments, only BY controls the target FDR. In practice, this means that we need a much higher donor samples size to detect a differential expression compared to paired experiments.

\textcolor{red}{Interestingly, our power analysis suggests that GLMM-BH achieves adequate power with 1000 cells per sample. Not much can be gained by going to 10,000 or more cells. Such cell counts are not uncommon in cytometry studies. Our findings suggest that \texttt{CytoGLMM} will not detect any differential expression for rare cell types with around 100 cells per sample. \texttt{Citrus} showed low power in our simulation analysis. This makes sense as \texttt{Citrus} was not intended to be used for predefined cell types---its main focus is cell type discovery.}

Overall, larger cell-level and donor-level correlations increase power and reduce the observed FDR. Hypothesis testing under arbitrary dependency structure is still an active research topic [@barber2015controlling; @candes2018panning; @fithian2020conditional]. What is easier to explain is the reduction in power and FDR as a function of increased cell-level variance. Research in measurement error models shows that increased uncertainty in measured covariates is linked to biased estimates [@fuller1987measurement; @carroll2006measurement]. 
<!-- The coefficient estimates are regularized—shrinking them towards zero—which translates into more conservative $p$-values -->
\textcolor{red}{For example, consider a scatter plot of experimental outcome (vertical axis) and one marker expression (horizontal axis). The goal is to fit a line so that we can predict the experimental outcome from the marker expression. Now assume that we measured the same marker with increased measurement error. This would spread out the the points along the horizontal axis, flatten the line fit, tilt it toward zero, and bias the regression coefficient towards zero.} In GLMMs, donor-level correlations have only a weak impact on power and observed FDR because we explicitly model correlations with a random effect term.

<!-- discuss pregnancy data results -->

\textcolor{red}{In addition to corroborating a differential expression of pSTAT1 in the original study} [@aghaeepour2017immune]\textcolor{red}{, we also found that pSTAT3 and pSTAT5 were differentially expressed in the NK cell population. This additional finding could be a result of the improved power of our method, but it could also be a result of the different regression analysis strategy. In the original study, the authors analyzed all cell types simultaneously. Such conditioning on other cell types could influence the differential expression estimates.} In general, biases in coefficient estimates of GLMs and GLMMs can occur when we leave out proteins from the analysis. Assume that we would like to relate variable protein $X$ to experimental condition $Y$. If there exists a second protein $Z$ both related to $X$ and $Y$, then $Z$ is called a confounder, and not including it in the analysis can change the coefficients estimates. In the pregnancy data, if we removed pSTAT1 from the analysis, the confidence intervals of pSTAT3 and pSTAT5 could change. Such a difference is expected if pSTAT1 is a confounder. If pSTAT1 is not a confounder, the coefficient estimates for pSTAT3 and pSTAT5 will be the same whether pSTAT1 is included or not. The change of coefficients depending on what markers are included in the model can have strong effects. We observed in some real datasets that one marker can make other markers change their sign depending on whether we include them or not. \textcolor{red}{In the pregnancy data, pSTAT5 flips sign from negative to positive after removing pSTAT1 from the analysis.} In such cases, we recommend keeping all markers in the analysis to avoid introducing confounding biases.

\textcolor{red}{We analyze 10 functional markers in the pregnancy data. \texttt{CytoGLMM} scales computationally to larger number of markers as GLMM can be implemented with the method of moments, and GLM with fast numerical optimization procedures. For example, a GLMM analysis on 40 markers, 16 samples, and 10,000 cells per sample takes 10 seconds on a laptop with an 2.3 GHz quad-core processor. There is however a statistical tradeoff as the effective sample size will be anywhere between the number of samples and the cells. To extend our methodology to more than two groups, we recommend to run a separate two-group \texttt{CytoGLMM} analysis on each pair, and combine the $p$-value tables---using the \texttt{summary} function---to control the overall FDR.}

<!-- discuss limitations -->

Our simulations are limited to a Poisson mixed effect model for protein marker expression. Our conclusions are only valid with respect to this model. The real data generating process might be different. Two main caveats are to be noted. First, we can only encode an experimental design comparing two groups. Second, we require gated cell types. To reduce the person-to-person bias of manual gating, we employed the _R_ package `openCyto` [@finak2014opencyto]. The curse of dimensionality makes it challenging to scale this approach to very high dimensional gating schemes. \textcolor{red}{For example, consider 20 gating markers and assume that each marker differentiates between two cell populations. This seemingly harmless gating procedure can produce $2^{20}$ or approximately one million possible cell types. In this setting, even large cell sample sizes might provide unreliable cell types estimates.}

<!-- discuss alternatives -->

A possible alternative to GLMMs are Generalized Estimating Equations (GEEs). GEEs are statistically more efficient when the covariance structure of the residuals are known. In our case, the covariance structure is unknown and needs to be estimated from the data. In most immunology studies, we only have a few donors without a given covariance structure (e.g. no time dependency), resulting in a hard and possibly unstable covariance estimation problem, which could result in an overall loss of efficiency [@wakefield2013bayesian].

# Conclusions

<!-- state clearly the main conclusions -->
We presented a conditional differential analysis to avoid biases arising from marker correlations. We built statistical models of the unsummarized expression data to maximize statistical power, and modeled patient heterogeneity to safeguard against false discoveries. The main difference between our and related procedures is that we assume that the cell type is known or can be estimated with high accuracy.
<!-- provide explanation of the importance and relevance of the study to the field -->
This assumption is reasonable in many studies with cytometry data. In our own work, we applied `CytoGLMM` in wide range of immunology studies: In @kronstad2018differential, \textcolor{red}{we identified differential expressions in CD112 and CD54 between the pandemic A/California/07/2009 and the seasonal A/Victoria/361/2011 influenza virus strains.} In @legars2019pregnancy, \textcolor{red}{we found increased expression of CD38 on CD56dim and CD56bright NK cells, and NKp46 on CD56dim NK cells in pregnant women compared to non-pregnant women.} In @vendrame2019tigit, \textcolor{red}{we found that TIGIT is upregulated on NK cells of untreated HIV+ women, but not in antiretroviral-treated women.} In @ranganath2020characterization, \textcolor{red}{we found that treatment with daclizumab beta increased expression of NKG2A and NKp44, and diminished expression of CD244, CD57, and NKp46 on CD56bright NK cells.} Most recently, in @zhao2020natural, \textcolor{red}{we found that in a cohort of Beninese sex workers and healthy controls NK cells from highly exposed seronegative individuals had increased expression of NKG2A, NKp30 and LILRB1, as well as the Fc receptor CD16, and decreased expression of DNAM-1, CD94, Siglec-7, and NKp44.}

<!-- next steps -->
\textcolor{red}{Both the GLM and GLMM method build on generalized linear models that can model other data types than binary responses. Therefore it would be possible to extend \texttt{CytoGLMM} to continuous response variables.} A more challenging next step is extending `CytoGLMM` to include more complicated experimental designs; e.g. twin studies [@brodin2015variation].

# Methods

## Preprocessing

We recommend that marker expressions be corrected for batch effects [@nowicka2017cytof; @chevrier2018compensation; @schuyler2019minimizing; @van2020cytonorm; @trussart2020removing] and transformed using variance stabilizing transformations to account for heteroskedasticity, for instance with an \textcolor{red}{inverse} hyperbolic sine transformation with the cofactor set to 150 for flow cytometry, and 5 for mass cytometry [@bendall2011single]. This transformation assumes a two-component model for the measurement error [@rocke1995two; @huber2003parameter] where small counts are less noisy than large counts. Intuitively, this corresponds to a noise model with additive and multiplicative noise depending on the magnitude of the marker expression; see [@holmes2019modern] for details.

## Generalized Linear Model (GLM)

The goal of the GLM is to find protein expression patterns that are associated with the condition of interest, such as a response to a stimulus. 
We set up the GLM to predict the experimental condition from protein marker expressions, thus our experimental conditions are response variables and marker expressions are explanatory variables. The response variable $Y_i$ is a binary variable encoding experimental condition as zero or one. The response variable can be modeled as a Bernoulli random variable with probability $\pi_i$ for each cell. Then we use the $\operatorname{logit}$ link to relate the linear model to binary responses. The linear model predicts the logarithm of the odds of the $i$th cell being $Y_i = 1$ instead of $Y_i = 0$. The linear model has one coefficient per protein marker $\beta_1,\dots,\beta_P$ and an intercept $\beta_0$. If $\pi_i$ is 0.5 then the cell could have come from either $Y_i = 1$ or $Y_i = 0$ with equal probability. If $\pi_i$ is either very close to one or zero, then the cell is strongly representative of a cell observed under $Y_i = 1$ or $Y_i = 0$, respectively. We observe the protein marker expressions $\boldsymbol{x}_i$. For each cell we measure $P$ protein markers.

The response probabilities $\pi_i$ are not observed directly, only $Y_i = y_i$ and $\boldsymbol{x}_i$ are observed. Note that $\boldsymbol{x}_i$ is observed with errors. Here, we make the approximating assumption that the covariates are fixed. Our results will show that this assumption is conservative and introduces a regularization of the estimated coefficients. We estimate $\pi_i$ from the data using maximum likelihood with the function `glm` in _R_. Our logistic regression model, which is part of a general class of GLMs, can be summarized in the following form:
$$
\begin{aligned}
Y_{i} & \sim \operatorname{Bernoulli}(\pi_{i}), \\
\log\left(\frac{\pi_i}{1-\pi_i}\right) & = \boldsymbol{x}_i^T\boldsymbol{\beta}.
\end{aligned}
$$

For likelihood inference, we use the nonparametric bootstrap and resample entire donors with replacement to preserve the cluster structure. At the cell-level, we resample cells with replacement within each donor. We build percentile confidence intervals and compute $p$-values by inverting the intervals assuming two-sided intervals with equal tails [@efron1994introduction]. 
We use the BH [@benjamini1995controlling] and BY [@benjamini2001control] procedures to control the FDR. 
We refer to GLM with BH control as GLM-BH, and with BY control as GLM-BY.

## Generalized Linear Mixed Model (GLMM)

We make additional modeling assumptions by adding a random effect term in the standard logistic regression model to account for the subject effect. The covariates $\boldsymbol{x}_{ij}$ are the same as in the fixed effects GLM, except now we have an additional index $j$ that indicates from which donor the cell was taken. Each cell $i$ maps to a donor $j$. The additional term $\boldsymbol{u}_j$ represents regression coefficients that vary by donor. The statistical model can be summarized as,
$$
\begin{aligned}
Y_{ij} & \sim \operatorname{Bernoulli}(\pi_{ij}), \\
\log\left(\frac{\pi_{ij}}{1-\pi_{ij}}\right) & = x_{ij}^T\boldsymbol{\beta} + x_{ij}^T\boldsymbol{u}_{j},
\end{aligned}
$$
with a multivariate normal distribution and covariance matrix $\boldsymbol{\Sigma}$ for the random effect term $\boldsymbol{u}_j$,
$$
\boldsymbol{u}_j \, | \, \boldsymbol{\Sigma} \sim \operatorname{Normal}\left(\boldsymbol{0}, \boldsymbol{\Sigma} \right).
$$
Analog to our GLM, we make the approximating assumption that the covariates are fixed.

The mixed effect model is a compromise between two extremes. On the one hand, we could estimate separate regression coefficients for each donor. This corresponds to random effects modeled with a multivariate normal distribution with infinite standard deviations and no constraint on how coefficients are related to each other. On the other hand, we could pool all donors into one group and ignore the donor information. This corresponds to a GLM with no random effects, with no additional variability besides the fixed effect term. A compromise between these two extremes is to estimate the standard deviations of the random effects from data, allowing the regression model to learn from the other donors. 
Mixed effects procedures are related to empirical Bayes procedures [@weber2019diffcyt]. The first step of an empirical Bayes procedure would estimate the mean and covariance matrix of the random effect term. The second step would fix the random effect parameters at their estimated values and estimate the fixed effect parameters. In contrast, the mixed effect procedure estimates the parameters of both steps jointly. This is possible for flow and mass cytometry data because of the relatively small number of proteins.

We use the method of moments as implemented in the _R_ package `mbest` to estimate the model parameters $\boldsymbol{\beta}$, $\boldsymbol{u}_j$, and $\boldsymbol{\Sigma}$. For likelihood inference, we use the asymptotic theory derived by @perry2017fast. The author showed that the sampling distribution of the estimated parameters can be approximated by a normal distribution. We use this mathematical alternative to the bootstrap method to create approximate confidence intervals and $p$-values. As in the GLM case, we use the BH and BY procedures to control the FDR. 
We refer to GLMM with BH control as GLMM-BH, and with BY control as GLMM-BY.

## Construction of Simulated Datasets

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{graphical_plmm}
\caption{\textcolor{red}{Graphical representation of the Poisson GLM used to construct the simulated datasets.}}
\label{fig:plmm}
\end{figure}

\textcolor{red}{We construct our simulated datasets by sampling from Poisson GLMs. In prior work, we confirmed---with predictive posterior checks---that Poisson GLMs with mixed effects provide a good fit to mass cytometry data on the same pregnancy dataset} [@seiler2019uncertainty]. We consider one underlying data generating mechanisms described by a hierarchical model for the $i$th cell and $j$th donor:
$$
\begin{aligned}
\boldsymbol{X}_{ij} & \sim \text{Poisson}(\boldsymbol{\lambda}_{ij}) \\
\log(\boldsymbol{\lambda}_{ij}) & = \boldsymbol{B}_{ij} + \boldsymbol{U}_j \\
\boldsymbol{B}_{ij} & \sim
\begin{cases} 
\text{Normal}(\boldsymbol{\delta}^{(0)}, \boldsymbol{\Sigma}_B) & \text{if } Y_{ij} = 0, \text{ cell unstimulated} \\
\text{Normal}(\boldsymbol{\delta}^{(1)}, \boldsymbol{\Sigma}_B) & \text{if } Y_{ij} = 1, \text{ cell stimulated}
\end{cases} \\
\boldsymbol{U}_j & \sim \text{Normal}(\boldsymbol{0}, \boldsymbol{\Sigma}_U).
\end{aligned}
$$
\textcolor{red}{Figure \ref{fig:plmm} shows a graphical representation of the hierarchical model.} The stimulus activates proteins and induces a difference in marker expression. We define the effect size to be the difference between expected expression levels of stimulated versus unstimulated cells on the $\log$-scale. All markers that belong to the active set \textcolor{red}{$C$}, have a non-zero effect size, whereas, all markers that are not, have a zero effect size:
$$
\begin{cases}
\delta^{(1)}_p - \delta^{(0)}_p > 0 & \text{if protein } p \text{ is in activation set } p \in C \\
\delta^{(1)}_{p'} - \delta^{(0)}_{p'} = 0 & \text{if protein } p' \text{ is not in activation set } p' \notin C.
\end{cases}
$$
Both covariance matrices have an autoregressive structure, 
$$
\begin{aligned}
\Omega_{rs} & = \rho^{|r-s|} \\ 
\boldsymbol{\Sigma} & = \operatorname{diag}(\boldsymbol{\sigma}) \, \boldsymbol{\Omega} \, \operatorname{diag}(\boldsymbol{\sigma}),
\end{aligned}
$$
\textcolor{red}{where $\Omega_{rs}$ is the $r$th row and $s$th column of the correlation matrix $\boldsymbol{\Omega}$.} We regulate two separate correlation parameters: a cell-level $\rho_B$ and a donor-level $\rho_U$ coefficient. Non-zero $\rho_B$ or $\rho_U$ induce a correlation between condition and marker expression even for markers with a zero effect size.

## Processing of Pregnancy Dataset

\textcolor{red}{We reproduce the original gating strategy according to the supplementary material (Figure S1) from} @aghaeepour2017immune \textcolor{red}{using the \textit{R} package \texttt{openCyto}} [@finak2014opencyto]. \textcolor{red}{In our analysis, we focus on the 178,872 NK cells. The number of cells per sample vary between 6,480 to 21,348. The full \texttt{openCyto} workflow is available as a vignette on our package website:}

* https://christofseiler.github.io/CytoGLMM/articles/pregnancy_dataset.html

# List of Abbreviations

* Generalized Linear Model (GLM)
* Generalized Linear Mixed Model (GLMM) 
* False Discovery Rate (FDR)
* Benjamini-Hochberg (BH)
* Benjamini–Yekutieli (BY)

# Declarations {-#declarations}

## Ethics Approval and Consent to Participate {-#ethics}

Not applicable

## Consent for Publication {-#consent}

Not applicable

## Availability of Data and Materials {-#availability}

All data analysed during this study are included in @aghaeepour2017immune.

All results and figures can be reproduced by running the manuscript _Rmd_ available on GitHub:

* https://github.com/christofseiler/CytoGLMM_BMC/

Our _R_ package is available on GitHub:

* https://github.com/christofseiler/CytoGLMM/

A vignette is available on our _R_ package website:

* https://christofseiler.github.io/CytoGLMM/articles/CytoGLMM.html

## Competing Interests {-#competing}

The authors declare that they have no competing interests.

## Funding {-#funding}

This work was supported by the National Institutes of Health [U01AI131302 to CAB and SH, R56AI124788 to CAB and SH, R21AI130523 to CAB and SH, DP1DA046089 to CAB, R21AI130532 to CAB, R01AI133698 to CAB, R21AI135287 to CAB, 5T32AI007290-29 to LMK, TL1TR001084 to EV, T32AI007502 to EV, 1F32AI126674 to LJS]; an A.P. Giannini fellowship [to LMK]; and a Stanford Child Health Research Institute postdoctoral fellowship [to MLG]. CAB is the Tashia and John Morgridge Endowed Faculty Scholar in Pediatric Translational Medicine from the Maternal Child Health Research Institute, and a Chan Zuckerberg Investigator.

## Authors' Contributions {-#authors}

CS, AMF, LMK, LJS, MLG, EV, CAB, and SH made substantial contributions to the conception of this work. 
CS drafted the initial manuscript. 
CAB and SH substantively revised it. 
CS created the software. 
CS, AMF, CAB, and SH designed and analyzed the simulation experiments.
LJS proposed to use the pregnancy data, and CS analyzed it. 
All authors read and approved the final manuscript.

## Acknowledgements {-#acknowledgements}

Not applicable

# References {.allowframebreaks}
