---
title: "`CytoGLMM`: Conditional Differential Analysis for Flow and Mass Cytometry Experiments"
author: "Christof Seiler$^{123}$, Anne-Maud Ferreira$^3$, Lisa M. Kronstad$^{457}$, Laura J. Simpson$^{45}$, \\\n Mathieu Le Gars$^{45}$, Elena Vendrame$^{45}$, Catherine A. Blish$^{456}$, and Susan Holmes$^3$"
date: "$^1$Department of Data Science and Knowledge Engineering, Maastricht University \\\n $^2$Mathematics Centre Maastricht, Maastricht University \\\n $^3$Department of Statistics, Stanford University \\\n $^4$Immunology Program, Stanford University School of Medicine \\\n $^5$Department of Medicine, Stanford University School of Medicine \\\n $^6$Chan Zuckerberg Biohub, San Francisco \\\n $^7$Department of Microbiology and Immunology, Midwestern University \\\n \\\n `r format(Sys.time(), '%B %d, %Y')`"
header-includes:
  - \usepackage{setspace}
  - \doublespacing
  - \usepackage{lineno}
  - \linenumbers
output:
  bookdown::pdf_document2: 
    toc: false
  bookdown::word_document2: 
    toc: false
bibliography: cytoglmm_manuscript.bib
abstract: |
  **Background:** Flow and mass cytometry are important modern immunology tools for measuring expression levels of multiple proteins on single cells. The goal is to better understand the mechanisms of responses on a single cell basis by studying differential expression of proteins. We focus on cell-specific differential analysis and one fixed cell type. In contrast, most current methods learn cell types and perform differential analysis jointly. Our narrower field of application allows us to define a more specific statistical model with easier to control statistical guarantees. **Results:** Differential analysis of marker expressions can be difficult due to marker correlations and inter-individual heterogeneity, particularly for studies of human immunology. We address these challenges with two multiple regression strategies: A bootstrapped generalized linear model and a generalized linear mixed model. On simulated datasets, we compare the robustness towards marker correlations and heterogeneity of both strategies. For paired experiments, we find that both strategies maintain the target false discovery rate under medium correlations and that mixed models are statistically more powerful under the correct model specification. For unpaired experiments, our results indicate that much larger patient sample sizes are required to detect differences. We illustrate the `CytoGLMM` _R_ package and workflow for both strategies on a pregnancy dataset. **Conclusions:** Our approach to find differential proteins in flow and mass cytometry data reduces biases arising from maker correlations and safeguards against false discoveries induced by patient heterogeneity.
---

```{r load_packages, echo=FALSE, warning=FALSE, message=FALSE}
library("CytoGLMM")
library("tidyverse")
library("magrittr")
library("broom")
library("RColorBrewer")
library("cowplot")
library("ggthemes")
library("MASS")
library("SummarizedExperiment")
library("logging")
library("lme4")
library("multcomp")
library("batchtools")
library("Matrix")
library("binaryLogic")
theme_set(theme_few())
setLevel("ERROR", container = "mbest.mhglm")
setLevel("ERROR", container = "mbest.mhglm.fit")
source("data.R")
source("experiment.R")
source("plotting.R")
```

# Background

Flow [@saeys2016computational] and mass cytometry [@bendall2011single] allow researchers to simultaneously assess expression patterns of a large number of proteins on individual cells, allowing deep interrogation of cellular responses. The goal of such studies is to better understand the mechanisms of responses on a single cell basis by defining protein expression patterns that are associated with a particular stimulus or experimental condition. Finding differentially expressed proteins can help identify how cells function across experimental conditions.

Statistical workflows to analyze data generated by flow and mass cytometry usually begin by clustering cells into both known and novel cell types. Many cluster algorithms are available [@lo2009flowclust; @finak2009merging; @qian2010elucidation; @zare2010data; @aghaeepour2011rapid; @qiu2011extracting; @ge2012flowpeaks; @shekhar2014automatic; @becher2014high; @naim2014swift; @meehan2014autogate; @van2015flowsom; @sorensen2015immunoclust; @levine2015data; @chen2016cytofkit; @samusik2016automated; @lee2017automated; @li2017gating; @theorell2019determination; @abdelaal2019predicting] and @weber2016comparison provide an informative benchmark comparison study of most of these algorithms. The cluster step is followed by a differential expression analysis between and within cell types. The most popular differential analysis tools are: `Citrus` [@bruggner2014automated], the `Bioconductor workflow` by @nowicka2017cytof, `cydar` [@lun2017testing], `CellCnn` [@arvaniti2017sensitive], and `diffcyt` [@weber2019diffcyt].

We can classify differential analysis methods into marginal regression---analyses that focus on individual markers---and multiple regression---analyses that work on multiple markers simultaneously. The `Bioconductor workflow` by @nowicka2017cytof, `cydar`, and `diffcyt` are marginal regression methods. The advantage of marginal regression approaches is that they allow for flexible experimental designs. The main disadvantage of this approach is the separate testing for differential expression for each protein---when studying a specific protein marker all the other markers are ignored. Therefore these methods are susceptible to biases induced by marker correlations.

`Citrus` and `CellCnn` are multiple regression methods. The advantage is that they can provide a conditional interpretation of the effect of a protein onto the outcome, and thus reduce the bias coming from marker correlations. The disadvantage is that `Citrus` summarizes protein expressions by taking the median for each cell type which can lead to a decrease in statistical power. The power decrease comes from the reduction in cell sample size from thousands of cells to one cell per sample. On the other hand, `cydar` uses a neural network for which it is currently unclear how to build confidence intervals, derive $p$-values, and control the number of falsely reported markers.

It is helpful to consider an example to further illustrate the differences between the marginal and the multiple regression method. Consider two intracellular proteins, *A* and *B*, that are part of the same signal transduction pathway. Assume that applying a stimulus to *A* activates *B*. Further assume that the stimulus does not directly activate *B*. If we performed separate differential analyses on protein *A* and *B*, we would observe differential expressions for both *A* and *B*, even though only *A* had been directly activated. In contrast, a multiple regression method would report *A* as differentially expressed given *B*, and *B* as not differentially expressed given *A*.

`CytoGLMM` implements multiple regression that accounts for marker correlations without the aforementioned limitations. The main difference between our method and current methods is that we focus on cell-specific differential analysis and one fixed cell type, whereas current methods (`Citrus`, `CellCnn`, `cydar`, and `diffcyt`) learn cell types and perform differential analysis jointly. The narrower field of application allows us to define a more specific statistical model with easier to control statistical guarantees. Only the `Bioconductor workflow` by @nowicka2017cytof focuses on specific cell types, but as mentioned before, they employ marginal regression which makes comparison to our multiple regression method difficult---as the two methods have different aims.

We present two versions of multiple regression: (i) A Generalized Linear Model (GLM) for unpaired samples. A GLM is a regression model that allows for a response and error terms that follow different distributions than the normal. (ii) A restricted Generalized Linear Mixed Model (GLMM), which is a GLM that allows for random and fixed effects, for paired samples---when the same donor provides two samples, one for each condition. GLMs and GLMMs are generalizations of least squares to data from the exponential family. In our case, we will use logistic regression to model the experimental condition with a Bernoulli distribution and link it to a linear model of marker expressions with the $\operatorname{logit}$ function. 

Our models depart from the classic model where the marker expressions are the response variables. In our GLMs, the experimental condition $Y$ is independent of the $j$th marker expression $X_j$ given the other markers $X_{-j}$ (all makers $X_1,\dots,X_P$ except the marker $X_j$) if and only if the $j$th regression coefficient is zero (for a mathematical proof of this statement see Proposition 2.2 in @candes2018panning). In contrast, the usual marginal regression analysis does not allow for such conditional statements. For instance, it would not allow us to rule out markers that are merely correlated with other makers but are independent of the experimental condition---as illustrated with the example earlier.

In summary, our two main contributions are:

1. We present a conditional differential analysis to avoid biases arising from marker correlations by using multiple regression instead of marginal regression.
2. We present two multiple regression strategies that work with the unsummarized expression data to maximize statistical power and account for patient heterogeneity to safeguard against false discoveries: (i) GLMs with a patient-level bootstrap, and (ii) GLMMs with a patient-level random effect.

Section \@ref(results) evaluates the statistical properties of both strategies implemented in our _R_ package `CytoGLMM` on different simulated datasets, and illustrates the full workflow for real pregnancy data. In Section \@ref(discussion), we discuss our results in terms of biases and confounders. In Section \@ref(methods), we review the statistical background for GLMs and GLMMs.

# Results

We first evaluate the GLM and GLMM procedures for both paired and unpaired samples on simulated datasets. We then test them on a real pregnancy dataset.

## Simulated Datasets

We generate simulated data with both cell and donor level variability. We allow for negative and positive correlations between markers and a wide range of correlation strengths. We simulate different scenarios ranging from weak to strong patient/cell variability. To make sure that we generate positive counts we use a Poisson noise model after transforming the generated expressions to positive real numbers using the exponential function. This is similar to using the log link function for Poisson GLMs. Overall, there are four main parameters: correlation $\rho_B$ and standard deviation $\sigma_B$ at the cell level, and correlation $\rho_U$ and standard deviation $\sigma_U$ at the donor level. Additionally, we can regulate the number of cells per sample and the number of donors per dataset. The differential expression signal is induced by shifting the mean vector on the logarithmic scale.

We study the differential expression of three out of 10 markers after simulating exposure of cells to an experimental condition with two levels: stimulated versus unstimulated cells. We consider one underlying data generating mechanisms described by a hierarchical model for the $i$th cell and $j$th donor:
$$
\begin{aligned}
X_{ij} & \sim \text{Poisson}(\lambda_{ij}) \\
\log(\lambda_{ij}) & = B_{ij} + U_j \\
B_{ij} & \sim
\begin{cases} 
\text{Normal}(\boldsymbol{\delta}^{(0)}, \boldsymbol{\Sigma}_B) & \text{if } Y_{ij} = 0, \text{ cell unstimulated} \\
\text{Normal}(\boldsymbol{\delta}^{(1)}, \boldsymbol{\Sigma}_B) & \text{if } Y_{ij} = 1, \text{ cell stimulated}
\end{cases} \\
U_j & \sim \text{Normal}(\boldsymbol{0}, \boldsymbol{\Sigma}_U).
\end{aligned}
$$
The stimulus activates three proteins and induces a difference in marker expression. We define the effect size to be the difference between expected expression levels of stimulated versus unstimulated cells on the $\log$-scale. We choose a set $C = 3$ of active markers. All markers that belong to the active set, have a non-zero effect size, whereas, all markers that are not, have a zero effect size:
$$
\begin{cases}
\delta^{(1)}_p - \delta^{(0)}_p > 0 & \text{if protein } p \text{ is in activation set } p \in C \\
\delta^{(1)}_{p'} - \delta^{(0)}_{p'} = 0 & \text{if protein } p' \text{ is not in activation set } p' \notin C.
\end{cases}
$$
Both covariance matrices have an autoregressive structure, 
$$
\begin{aligned}
\Omega_{rs} & = \rho^{|r-s|} \\ 
\boldsymbol{\Sigma} & = \operatorname{diag}(\boldsymbol{\sigma}) \, \boldsymbol{\Omega} \, \operatorname{diag}(\boldsymbol{\sigma}).
\end{aligned}
$$
We regulate two separate correlation parameters: a cell-level $\rho_B$ and a donor-level $\rho_U$ coefficient. Non-zero $\rho_B$ or $\rho_U$ induce a correlation between condition and marker expression even for markers with a zero effect size.

```{r echo=FALSE, eval=FALSE}
# run on cluster
slurm_settings = "slurm_batchtools.tmpl"
current_time = Sys.time() %>%
  str_replace_all(":","") %>%
  str_replace_all("-| ","_")
reg = makeRegistry(file.dir = paste0("registry_",current_time),
                   source = c("diffcyt.R"),
                   packages = c("CytoGLMM", "tidyverse", "magrittr", "MASS", 
                                "lme4", "multcomp", "Matrix", "binaryLogic"))
#reg$cluster.functions = makeClusterFunctionsMulticore(ncpus = 8)
reg$cluster.functions = makeClusterFunctionsSlurm(slurm_settings, 
                                                  scheduler.latency = 30,
                                                  fs.latency = 30)
saveRegistry(reg)
tb_args_paired = tidyr::crossing(
  n_sample = 16,
  fdr = 0.05,
  pi = 0,
  paired = TRUE,
  beta_treatment = log(24.7),
  beta_control = log(22.9),
  n_markers = 10,
  bias = 0,
  n_true = 3,
  rho_b = -seq(0, 0.8, 0.4),
  rho_u = -seq(0, 0.8, 0.4),
  sigma_b = seq(0, 1, 0.5),
  sigma_u = seq(0, 1, 0.5),
  n_cells = 1000,
  seed = 1:100
  )
tb_args_unpaired = tidyr::crossing(
  n_sample = 16, # seq(4, 32, 2)
  fdr = 0.05,
  pi = 0,
  paired = FALSE,
  beta_treatment = log(22.9+15),
  beta_control = log(22.9),
  n_markers = 10,
  bias = 0,
  n_true = 3,
  rho_b = -seq(0, 0.8, 0.4), # 0
  rho_u = -seq(0, 0.8, 0.4), # 0
  sigma_b = seq(0, 1, 0.5), # 1
  sigma_u = seq(0, 1, 0.5), # 1
  n_cells = 1000,
  seed = 1:100
  )
tb_args_n_sample = tidyr::crossing(
  n_sample = seq(4, 32, 2),
  fdr = 0.05,
  pi = 0,
  paired = TRUE,
  beta_treatment = log(24.7),
  beta_control = log(22.9),
  n_markers = 10,
  bias = 0,
  n_true = 3,
  rho_b = 0,
  rho_u = 0,
  sigma_b = 1,
  sigma_u = 1,
  n_cells = 1000,
  seed = 1:100
  )
tb_args = bind_rows(tb_args_paired, tb_args_unpaired)
#tb_args = tb_args_n_sample
ids =  batchMap(fun = experiment, args = tb_args, reg = reg)
n_chunks = 900
time_per_experiment = 10 # in minutes
ids[, chunk := chunk(job.id, n.chunks = n_chunks)] # group into 900 chunks
submitJobs(ids = ids, reg = reg,
           resources = list(ncpus = 1, # cores per job
                            memory = 8000, # MB memory per job
                            walltime = round(nrow(tb_args)/n_chunks*time_per_experiment) # minutes per job
                            ))
# expires only after 7 days to handle cluster instability
waitForJobs(sleep = 60, expire.after = 10080)
getStatus(reg = reg)
findErrors(reg = reg)
getErrorMessages(reg = reg)
# by setting missing.val to NULL, we impute failed jobs with NULL
tb_experiment = reduceResultsList(missing.val = NULL, reg = reg) %>% bind_rows()
write_csv(tb_experiment, path = "tb_experiment_paired_unpaired.csv")
#write_csv(tb_experiment, path = "tb_experiment_n_sample.csv")
# clean up
#removeRegistry()
```

```{r echo=FALSE, message=FALSE, eval=TRUE}
tb_experiment_paired_unpaired = read_csv("tb_experiment_paired_unpaired.csv")
tb_experiment_n_sample = read_csv("tb_experiment_n_sample.csv")
```

```{r echo=FALSE, message=FALSE}
tb_summary = tb_experiment_paired_unpaired %>% 
  group_by(fdr, paired, n_markers, beta_treatment, beta_control, bias, 
           n_true, rho_b, rho_u, sigma_b, sigma_u, n_cells, method) %>% 
  summarize(FDR = mean(fdp), power = mean(power)) %>%
  ungroup()
tb_summary %<>% mutate(effect_size = round(
  exp(beta_treatment) - exp(beta_control), digits = 1)
  )
```

We performed simulations with a variety of different parameters. All simulations have 16 samples. For paired samples, those 16 samples come from 8 donors. For unpaired samples, those 16 samples come from 16 donors. Each sample has 1,000 cells. We compared the observed False Discovery Rate (FDR) and the power. The FDR measures the statistical type 1 errors, the expected proportion of falsely declared discoveries over the total number of reported discoveries. The statistical power represents the proportion of correctly reported discoveries over the total number of true discoveries.

```{r experiment-paired, echo=FALSE, fig.height=5, fig.width=10, out.width="100%", fig.align="center", eval=TRUE, fig.cap="Summary of experiments with 1,000 cells per sample averaged over 100 runs. The horizontal dashed line represents the target FDR. Postfixes BH and BY stand for the respective FDR control procedure. Subscripts $B$ and $U$ indicate cell and donor-level standard deviation $\\sigma$ and correlation $\\rho$, respectively.", fig.wide=FALSE, warning=FALSE}
plot_grid(
  plot_cor(tb_summary %>% 
             filter(method %in% c("GLM-BH", "GLM-BY", "GLMM-BH", "GLMM-BY")), 
           .sigma_b = 1, .sigma_u = 1, .paired = TRUE),
  plot_sig(tb_summary %>% 
             filter(method %in% c("GLM-BH", "GLM-BY", "GLMM-BH", "GLMM-BY")), 
           .rho_b = 0, .rho_u = 0, .paired = TRUE)  
)
```

```{r experiment-unpaired, echo=FALSE, fig.height=5, fig.width=10, out.width="100%", fig.align="center", eval=TRUE, fig.cap="Summary of experiments with 1,000 cells per sample averaged over 100 runs. The horizontal dashed line represents the target FDR. Postfixes BH and BY stand for the respective FDR control procedure. Subscripts $B$ and $U$ indicate cell and donor-level standard deviation $\\sigma$ and correlation $\\rho$, respectively.", fig.wide=FALSE, warning=FALSE}
plot_grid(
  plot_cor(tb_summary %>% 
             filter(method %in% c("GLM-BH", "GLM-BY")),
           .sigma_b = 1, .sigma_u = 1, .paired = FALSE),
  plot_sig(tb_summary %>% 
             filter(method %in% c("GLM-BH", "GLM-BY")), 
           .rho_b = 0, .rho_u = 0, .paired = FALSE)
)
```

Figures \@ref(fig:experiment-paired) and \@ref(fig:experiment-unpaired) show a summary averaged over 100 runs for paired sample and unpaired sample experiments with effect size $\delta_p^{(1)}-\delta_p^{(0)} = 1.8$ and $\delta_p^{(1)}-\delta_p^{(0)} = 15$, respectively, and varying standard deviation $\sigma$ and correlation $\rho$ parameters. The dashed lines indicate the target FDR of $0.05$. 

First, let's consider the paired samples experiment. The plots on the left show results when we vary cell and donor-level correlations at a fixed amount of cell $\sigma_B = 1$ and donor $\sigma_U = 1$ marker standard deviations. We observe only small differences across donor correlations $\rho_U$ of a small increase of power with increasing correlation. In contrast, there are large increases of power as a function of cell correlations $\rho_B$. In the panel of plots on the right, we set both correlations to zero and vary the marker standard deviations. In this setting, we again observe major changes with increasing standard deviations at the cell-level $\sigma_B$: the larger the cell-level variability, the lower the power. This is also true for donor-level variability, though to a much lesser extent. FDR is controlled below its target level under medium cell-level marker correlations ($| \rho_B | \le  0.4$) except when cell variability is at zero $\sigma_B = 0$, and donor variability is at one $\sigma_U = 1$. As expected, the Benjamini–Yekutiel (BY) procedure is more conservative than the Benjamini-Hochberg (BH) procedure, that is both FDR and power are lower. Interestingly, power increases with cell-level correlations $\rho_B$, and is virtually unaffected by donor-level correlations $\rho_U$.
<!--
Additional simulation experiments on null-data showed that the $p$-values under zero effect size $\delta$ a skewed toward one with a non-zero cell-level variation. 
-->
Overall, GLMM methods are more powerful than GLM methods. Figure \@ref(fig:experiment-nsamples) shows simulations for power and FDR with varying numbers of paired samples. Both cell and donor standard deviations are set to $\sigma_B = \sigma_U = 1$, and correlations are set to $\rho_B = \rho_U = 0$. An efficiency gain is clearly visible when we compare how many paired samples are needed to achieve 80% power. We observe that for GLMMs we need 7 paired samples to exceed the 80% power threshold, whereas for GLMs we need 13 paired samples to achieve the same. 

```{r experiment-nsamples, echo=FALSE, fig.height=5, fig.width=5, out.width="48%", fig.align="center", eval=TRUE, fig.cap="Summary of experiments with 1,000 cells per sample averaged over 100 runs. Power: The horizontal dashed line represents a power of 0.8. FDR: The horizontal dashed line represents the target FDR of 0.05.", fig.wide=FALSE, warning=FALSE, message=FALSE}
tb_experiment_n_sample %<>% filter(paired)
tb_experiment_n_sample %<>% filter(method %in% c("GLM-BH", "GLM-BY", "GLMM-BH", "GLMM-BY"))
tb_summary = tb_experiment_n_sample %>% 
  group_by(fdr, paired, n_markers, beta_treatment, beta_control, bias, 
           n_true, rho_b, rho_u, sigma_b, sigma_u, n_cells, method, n_samples) %>% 
  summarize(FDR = mean(fdp), power = mean(power)) %>%
  ungroup()
tb_summary %<>% mutate(effect_size = round(
  exp(beta_treatment) - exp(beta_control), digits = 1)
  )
tb_summary %<>% mutate(n_pairs = n_samples/2)
p_power = ggplot(tb_summary, aes(n_pairs, power, color = method)) +
  geom_line() + 
  geom_point() +
  geom_hline(yintercept = 0.8, linetype = "dashed", alpha = 0.5) +
  geom_vline(xintercept = c(7, 13), linetype = "dashed", alpha = 0.5) +
  ggtitle("Power") +
  scale_color_few() +
  theme(axis.title.y = element_blank(), panel.spacing.x = unit(1, "lines")) +
  ylim(0, 1)
p_fdr = ggplot(tb_summary, aes(n_pairs, FDR, color = method)) +
  geom_line() + 
  geom_point() +
  geom_hline(yintercept = unique(tb_summary$fdr), linetype = "dashed", alpha = 0.5) +
  ggtitle("FDR") +
  scale_color_few() +
  theme(axis.title.y = element_blank(), panel.spacing.x = unit(1, "lines")) +
  ylim(0, 0.05)
plot_grid(p_power, p_fdr, nrow = 2)
```

In the unpaired samples experiment, we only show GLM results as the GLMM results have zero power, there is no data to estimate the donor-level random effect term. We observe up to 20% FDR with a target FDR of 5%. To have non-zero power we need to increase the effect size to 15 (in comparison, for paired experiments the effect size is set to 1.8). Furthermore, FDR is only controlled under medium cell-level marker correlations using the more conservative BY procedure, with BH exceeding $0.05$ in most scenarios except when we have zero donor-level variability $\sigma_U = 0$. As before, BY comes with a loss of power. 

## Experimental Dataset

We reanalyze a recently published dataset on the maternal immune system during pregnancy [@aghaeepour2017immune]. The study provides a rich mass cytometry dataset collected at four time points during pregnancy in two cohorts. The authors isolated cells from blood samples and stimulated them with several activation factors. The goal was to explain how immune cells react to these stimuli, and how these reactions change throughout pregnancy. Findings from such experiments might identify immunological deviations implicated in pregnancy-related pathologies.

The authors collected data at early, mid, late pregnancy, and six weeks postpartum. Samples were left unstimulated or stimulated. Stimulation conditions included: $\text{interferon-}\alpha\text{2A}$ ($\text{IFN}\alpha$), lipopolysaccharide, and a cocktail of interleukins (ILs) containing IL-2 and IL-6. They processed the samples on a CyTOF 2.0 mass cytometer instrument, and bead normalized the data to account for signal variation over time from changes in instrument performance [@finck2013normalization].

In our analysis, we focus on comparing early (first trimester, $Y_i = 0$) with late (third trimester, $Y_i = 1$) pregnancy samples stimulated with IFN$\alpha$ in the first cohort of 16 women. We gate cells into cell types and organize them in a data frame. We follow the gating scheme detailed in [@aghaeepour2017immune] and define 12 cell types using the _R_ package `openCyto` [@finak2014opencyto]:
memory CD4 positive T cells (CD4+Tmem), naive CD4 positive T cells (CD4+Tnaive),
memory CD8 positive T cells (CD8+Tmem), naive CD8 positive T cells (CD8+Tnaive),
$\gamma\delta$T cells (gdT), regulatory T memory cells (Tregsmem), regulatory T naive cells (Tregsnaive), B cells, classical monocytes (cMC), intermediate monocytes (intMC), non-classical monocytes (ncMC), and Natural Killer cells (NK). Out of the 32 protein markers measured on each cell, the authors defined 22 markers as gating markers, and 10 as functional markers. The functional markers are pSTAT1, pSTAT3, pSTAT5, pNF$\kappa$B, total I$\kappa$B, pMAPKAPK2, pP38, prpS6, pERK1/2, and pCREB (in plots Greek symbols are replaced by Latin symbols). 

We plot the maximum likelihood (GLM) and the method of moments estimates (GLMM) with 95\% confidence intervals for the fixed effects $\boldsymbol{\beta}$ (Figure \@ref(fig:pregnancy)). The estimates are on the $\log$-odds scale. We see that pSTAT1 is a strong predictor of the third trimester. This means that one unit increase in the transformed marker expression makes it between $\exp(1) = 2.7$ to $\exp(1.5) = 4.5$ (95\% confidence interval for GLMM) more likely to be a cell from the third trimester, while holding the other markers constant. pSTAT3 and pSTAT5 have negative coefficients. This means pSTAT3 and pSTAT5 predict the first trimester, while holding the other markers constant. Only pSTAT1, pSTAT3, and pSTAT5 are below an FDR of 0.05. Our results corroborate previous findings by @aghaeepour2017immune reporting an increase of pSTAT1 during the third trimester for IFN$\alpha$ stimulated samples.

```{r echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
df = load_data()
protein_names = names(df)[4:13]
df %<>% dplyr::mutate_at(protein_names, function(x) asinh(x/5))
df %<>% dplyr::filter(celltype == "NK")
glm_fit = CytoGLMM::cytoglm(df, 
                            num_boot = 1000,
                            protein_names = protein_names,
                            condition = "condition", 
                            group = "donor")
glmm_fit = CytoGLMM::cytoglmm(df, 
                              protein_names = protein_names,
                              condition = "condition", 
                              group = "donor")
```

```{r pregnancy, fig.height=3, fig.width=8, fig.align="center", echo=FALSE, cache=TRUE, fig.cap="Methods comparison between bootstrap GLM (cytoglm) and GLMM (cytoglmm). The horizontal axes are on the log-odds scale. The vertical axes are the protein markers.", out.width = "70%", warning=FALSE}
plot_grid(
  plot(glm_fit) + 
    ggtitle("cytoglm") + 
    xlim(c(-0.7, 1.5)), 
  plot(glmm_fit) + 
    ggtitle("cytoglmm") +
    xlim(c(-0.7, 1.5))
  )
```

# Discussion

<!-- high level overview -->

Our new _R_ package `CytoGLMM` is applicable to a wide range of cytometry studies. Besides comparisons on paired samples, where samples are available for the same subject under different experimental conditions, our `CytoGLMM` is applicable to unpaired samples, where samples are collected on two separate groups of individuals.

<!-- discuss simulation results -->

Our simulation experiments compare multiple regression GLM and GLMM, as implemented in `cytoglm` and `cytoglmm` in our _R_ package. In simulated paired samples experiments, both GLMM with Benjamini-Hochberg (GLMM-BH) and Benjamini–Yekutieli (GLMM-BY) procedures control the FDR below the target FDR under cell-level marker correlations with an autoregressive structure with correlations up to $\pm0.4$. GLMM methods are more powerful than GLM methods for paired samples. GLMM methods can account for the patient-to-patient variation in the model, whereas GLM methods treat this variation as noise, which results in noisier and thus less powerful estimates. For unpaired samples, we are forced to use the nonparametric bootstrap method for GLMs because there are no paired samples available to estimate the random effect term. In simulated unpaired experiments, only BY controls the target FDR. In practice, this means that we need a much higher donor samples size to detect a differential expression compared to paired experiments.

Overall, larger cell-level and donor-level correlations increase power and reduce the observed FDR. Hypothesis testing under arbitrary dependency structure is still an active research topic [@barber2015controlling; @candes2018panning; @fithian2020conditional]. What is easier to explain is the reduction in power and FDR as a function of increased cell-level variance. Research in measurement error models shows that increased uncertainty in measured covariates is linked to biased estimates. The coefficient estimates are regularized—shrinking them towards zero—which translates into more conservative $p$-values; for extensive literature on this topic see @fuller1987measurement and @carroll2006measurement. In GLMMs, donor-level correlations have only a weak impact on power and observed FDR because we explicitly model correlations with a random effect term.

<!-- discuss pregnancy data results -->

In general, biases in coefficient estimates of GLMs and GLMMs can occur when we leave out proteins from the analysis. Assume that we would like to relate variable protein $X$ to experimental condition $Y$. If there exists a second protein $Z$ both related to $X$ and $Y$, then $Z$ is called a confounder, and not including it in the analysis can change the coefficients estimates. In the pregnancy data, if we removed pSTAT1 from the analysis, the confidence intervals of pSTAT3 and pSTAT5 could change. Such a difference is expected if pSTAT1 is a confounder. If pSTAT1 is not a confounder, the coefficient estimates for pSTAT3 and pSTAT5 will be the same whether pSTAT1 is included or not. The change of coefficients depending on what markers are included in the model can have strong effects. We have observed that in some real datasets that one marker can make other markers change their sign depending on whether we include them or not. In such cases, we recommend keeping all markers in the analysis to avoid introducing confounding biases.

<!-- discuss limitations -->

Our simulations are limited to a Poisson mixed effect model for protein marker expression. Our conclusions are only valid with respect to this model. The real data generating process might be different. Two main caveats are to be noted. First, we can only encode an experimental design comparing two groups. Second, we require gated cell types. To reduce the person-to-person bias of manual gating, we employed the _R_ package `openCyto` [@finak2014opencyto]. The curse of dimensionality makes it challenging to scale this approach to very high dimensional gating schemes.

<!-- discuss alternatives -->

A possible alternative to GLMMs are Generalized Estimating Equations (GEEs). GEEs are statistically more efficient when the covariance structure of the residuals are known. In our case, the covariance structure is unknown and needs to be estimated from the data. In most immunology studies, we only have a few donors without a given covariance structure (e.g. no time dependency), resulting in a hard and possibly unstable covariance estimation problem, which could result in an overall loss of efficiency [@wakefield2013bayesian].

# Conclusions

<!-- state clearly the main conclusions -->
We presented a conditional differential analysis to avoid biases arising from marker correlations. We built statistical models of the unsummarized expression data to maximize statistical power, and modeled patient heterogeneity to safeguard against false discoveries. The main difference between our and related procedures is that we assume that the cell type is known or can be estimated with high accuracy.
<!-- provide explanation of the importance and relevance of the study to the field -->
This assumption is reasonable in many studies with cytometry data. In our own work, we applied `CytoGLMM` in wide range of immunology studies: comparison between influenza strains [@kronstad2018differential], comparison between pregnant and non-pregnant women [@legars2019pregnancy], comparison between healthy controls and HIV+ individuals [@vendrame2019tigit], comparison between multiple sclerosis patients treated with daclizumab beta or placebo [@ranganath2020characterization], and comparison between Beninese sex workers and healthy controls [@zhao2020natural]. 
<!-- next steps -->
Our next step is extending `CytoGLMM` to include more complicated experimental designs; e.g. twin studies [@brodin2015variation].

# Methods

## Preprocessing

We recommend that marker expressions be corrected for batch effects [@nowicka2017cytof; @chevrier2018compensation; @schuyler2019minimizing; @van2020cytonorm; @trussart2020removing] and transformed using variance stabilizing transformations to account for heteroskedasticity, for instance with a hyperbolic sine transformation with the cofactor set to 150 for flow cytometry, and 5 for mass cytometry [@bendall2011single]. This transformation assumes a two-component model for the measurement error [@rocke1995two; @huber2003parameter] where small counts are less noisy than large counts. Intuitively, this corresponds to a noise model with additive and multiplicative noise depending on the magnitude of the marker expression; see [@holmes2019modern] for details.

## Generalized Linear Model (GLM)

The goal of the GLM is to find protein expression patterns that are associated with the condition of interest, such as a response to a stimulus. 
We set up the GLM to predict the experimental condition from protein marker expressions, thus our experimental conditions are response variables and marker expressions are explanatory variables. The response variable $Y_i$ is a binary variable encoding experimental condition as zero or one. The response variable can be modeled as a Bernoulli random variable with probability $\pi_i$ for each cell. Then we use the $\operatorname{logit}$ link to relate the linear model to binary responses. The linear model predicts the logarithm of the odds of the $i$th cell being $Y_i = 1$ instead of $Y_i = 0$. The linear model has one coefficient per protein marker $\beta_1,\dots,\beta_P$ and an intercept $\beta_0$. If $\pi_i$ is 0.5 then the cell could have come from either $Y_i = 1$ or $Y_i = 0$ with equal probability. If $\pi_i$ is either very close to one or zero, then the cell is strongly representative of a cell observed under $Y_i = 1$ or $Y_i = 0$, respectively. We observe the protein marker expressions $\boldsymbol{x}_i$. For each cell we measure $P$ protein markers.

The response probabilities $\pi_i$ are not observed directly, only $Y_i = y_i$ and $\boldsymbol{x}_i$ are observed. Note that $\boldsymbol{x}_i$ is observed with errors. Here, we make the approximating assumption that the covariates are fixed. Our results will show that this assumption is conservative and introduces a regularization of the estimated coefficients. We estimate $\pi_i$ from the data using maximum likelihood with the function `glm` in _R_. Our logistic regression model, which is part of a general class of GLMs, can be summarized in the following form:
$$
\begin{aligned}
Y_{i} & \sim \operatorname{Bernoulli}(\pi_{i}), \\
\log\left(\frac{\pi_i}{1-\pi_i}\right) & = \boldsymbol{x}_i^T\boldsymbol{\beta}.
\end{aligned}
$$

For likelihood inference, we use the nonparametric bootstrap and resample entire donors with replacement to preserve the cluster structure. At the cell-level, we resample cells with replacement within each donor. We build percentile confidence intervals and compute $p$-values by inverting the intervals assuming two-sided intervals with equal tails [@efron1994introduction]. 
We use the BH [@benjamini1995controlling] and BY [@benjamini2001control] procedures to control the FDR. 
We refer to GLM with BH control as GLM-BH, and with BY control as GLM-BY.

## Generalized Linear Mixed Model (GLMM)

We make additional modeling assumptions by adding a random effect term in the standard logistic regression model to account for the subject effect. The covariates $\boldsymbol{x}_{ij}$ are the same as in the fixed effects GLM, except now we have an additional index $j$ that indicates from which donor the cell was taken. Each cell $i$ maps to a donor $j$. The additional term $\boldsymbol{u}_j$ represents regression coefficients that vary by donor. The statistical model can be summarized as,
$$
\begin{aligned}
Y_{ij} & \sim \operatorname{Bernoulli}(\pi_{ij}), \\
\log\left(\frac{\pi_{ij}}{1-\pi_{ij}}\right) & = x_{ij}^T\boldsymbol{\beta} + x_{ij}^T\boldsymbol{u}_{j},
\end{aligned}
$$
with a multivariate normal distribution and covariance matrix $\boldsymbol{\Sigma}$ for the random effect term $\boldsymbol{u}_j$,
$$
\boldsymbol{u}_j \, | \, \boldsymbol{\Sigma} \sim \operatorname{Normal}\left(\boldsymbol{0}, \boldsymbol{\Sigma} \right).
$$
Analog to our GLM, we make the approximating assumption that the covariates are fixed.

The mixed effect model is a compromise between two extremes. On the one hand, we could estimate separate regression coefficients for each donor. This corresponds to random effects modeled with a multivariate normal distribution with infinite standard deviations and no constraint on how coefficients are related to each other. On the other hand, we could pool all donors into one group and ignore the donor information. This corresponds to a GLM with no random effects, with no additional variability besides the fixed effect term. A compromise between these two extremes is to estimate the standard deviations of the random effects from data, allowing the regression model to learn from the other donors. 
Mixed effects procedures are related to empirical Bayes procedures [@weber2019diffcyt]. The first step of an empirical Bayes procedure would estimate the mean and covariance matrix of the random effect term. The second step would fix the random effect parameters at their estimated values and estimate the fixed effect parameters. In contrast, the mixed effect procedure estimates the parameters of both steps jointly. This is possible for flow and mass cytometry data because of the relatively small number of proteins.

We use the method of moments as implemented in the _R_ package `mbest` to estimate the model parameters $\boldsymbol{\beta}$, $\boldsymbol{u}_j$, and $\boldsymbol{\Sigma}$. For likelihood inference, we use the asymptotic theory derived by @perry2017fast. The author showed that the sampling distribution of the estimated parameters can be approximated by a normal distribution. We use this mathematical alternative to the bootstrap method to create approximate confidence intervals and $p$-values. As in the GLM case, we use the BH and BY procedures to control the FDR. 
We refer to GLMM with BH control as GLMM-BH, and with BY control as GLMM-BY.

# List of Abbreviations

* Generalized Linear Model (GLM)
* Generalized Linear Mixed Model (GLMM) 
* False Discovery Rate (FDR)
* Benjamini-Hochberg (BH)
* Benjamini–Yekutieli (BY)

# Declarations {-#declarations}

## Ethics Approval and Consent to Participate {-#ethics}

Not applicable

## Consent for Publication {-#consent}

Not applicable

## Availability of Data and Materials {-#availability}

All data analysed during this study are included in @aghaeepour2017immune.

All results and figures can be reproduced by running the manuscript _Rmd_ available on GitHub:

* https://github.com/christofseiler/CytoGLMM_BMC/

## Competing Interests {-#competing}

The authors declare that they have no competing interests.

## Funding {-#funding}

This work was supported by the National Institutes of Health [U01AI131302 to CAB and SH, R56AI124788 to CAB and SH, R21AI130523 to CAB. and SH, DP1DA046089 to CAB, R21AI130532 to CAB, R01AI133698 to CAB, R21AI135287 to CAB, 5T32AI007290-29 to LMK, TL1TR001084 to EV, T32AI007502 to EV, 1F32AI126674 to LJS]; an A.P. Giannini fellowship [to LMK]; and a Stanford Child Health Research Institute postdoctoral fellowship [to MLG]. CAB is the Tashia and John Morgridge Endowed Faculty Scholar in Pediatric Translational Medicine from the Maternal Child Health Research Institute, and a Chan Zuckerberg Investigator.

## Authors' Contributions {-#authors}

All authors made substantial contributions to the conception of this work. 
CS drafted the initial manuscript. 
CAB and SH substantively revised it. 
CS created the software. 
CS, AMF, CAB, and SH designed and analyzed the simulation experiments.
LJS proposed to use the pregnancy data, and CS analyzed it. 
All authors read and approved the final manuscript.

## Acknowledgements {-#acknowledgements}

Not applicable

# Supplementary Material {-#supplementary-material}

## `CytoGLMM` _R_ Package {-#cytoglmm-r-package}

Our _R_ package is available on GitHub:

* https://github.com/christofseiler/CytoGLMM/

A vignette is available on our _R_ package website:

* https://christofseiler.github.io/CytoGLMM/

## `CytoGLMM` Workflow {-#cytoglmm-workflow}

```{r echo=FALSE}
df = load_data()
```

Here we illustrate a complete `CytoGLMM` workflow in _R_. Prepare data frame marker counts and sample information.

```{r}
str(df)
```

Select functional marker of interest.

```{r}
protein_names
```

Transform counts.

```{r}
df %<>% dplyr::mutate_at(protein_names, function(x) asinh(x/5))
```

Subset to one celltype.

```{r}
df %<>% dplyr::filter(celltype == "NK")
```

Fit the `cytoglm` model with `1000` bootstrap samples.

```{r cache=TRUE}
glm_fit = CytoGLMM::cytoglm(df, 
                            protein_names = protein_names,
                            condition = "condition", 
                            group = "donor", 
                            num_boot = 1000)
```

Fit the `cytoglmm` model.

```{r cache=TRUE, warning=FALSE}
glmm_fit = CytoGLMM::cytoglmm(df, 
                              protein_names = protein_names,
                              condition = "condition", 
                              group = "donor")
```

Use `print(glm_fit)` or `print(glmm_fit)` on the fitted object to obtain some additional details of the model that we just fitted.

Plot differential analysis results.

```{r fig.height=3, fig.width=4, cache=TRUE, out.width="35%", warning=FALSE}
plot(glm_fit)
plot(glmm_fit)
```

Extract $p$-values.

```{r}
summary(glm_fit)
summary(glmm_fit)
```

Filter adjusted $p$-values at some threshold.

```{r}
summary(glm_fit) %>% 
  dplyr::filter(pvalues_adj < 0.05)
summary(glmm_fit) %>% 
  dplyr::filter(pvalues_adj < 0.05)
```

# References {.allowframebreaks}
